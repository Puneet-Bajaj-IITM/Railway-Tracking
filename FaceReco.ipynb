{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT27_Zqlrgk-"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/Face_Recognition_Model.zip\n",
        "# !cd /content/Face_Recognition_Model\n",
        "# !wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "# !chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "# !bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "# import sys\n",
        "# sys.path.append('/usr/local/lib/python3.7/site-packages/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kBf-p8duXIX",
        "outputId": "b8058b05-2945-4b0d-b12c-f8237b3dec02"
      },
      "outputs": [],
      "source": [
        "!conda create -n myenv python=3.7.6\n",
        "!conda activate myenv\n",
        "!python --version\n",
        "!conda install ipykernel\n",
        "!python -m ipykernel install --user --name=myenv\n",
        "!pip install --upgrade jupyter_client\n",
        "!pip install tensorflow\n",
        "!pip install pandas\n",
        "!conda install -c anaconda pillow\n",
        "!conda install -c anaconda matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "p6I8PzY3q0_3",
        "outputId": "29f7d00c-3574-4261-8a80-6ab684450a8d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from numpy import genfromtxt\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "import fr_utils\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "\n",
        "K.set_image_data_format('channels_first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_Zxi603q0_6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inception_block_1a(X):\n",
        "    \"\"\"\n",
        "    Implementation of an inception block\n",
        "    \"\"\"\n",
        "\n",
        "    X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name ='inception_3a_3x3_conv1')(X)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name = 'inception_3a_3x3_bn1')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "    X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3a_3x3_conv2')(X_3x3)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_3x3_bn2')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "\n",
        "    X_5x5 = Conv2D(16, (1, 1), data_format='channels_first', name='inception_3a_5x5_conv1')(X)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn1')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "    X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "    X_5x5 = Conv2D(32, (5, 5), data_format='channels_first', name='inception_3a_5x5_conv2')(X_5x5)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn2')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3a_pool_conv')(X_pool)\n",
        "    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_pool_bn')(X_pool)\n",
        "    X_pool = Activation('relu')(X_pool)\n",
        "    X_pool = ZeroPadding2D(padding=((3, 4), (3, 4)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3a_1x1_conv')(X)\n",
        "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_1x1_bn')(X_1x1)\n",
        "    X_1x1 = Activation('relu')(X_1x1)\n",
        "\n",
        "    # CONCAT\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1RS4wKOq0_8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inception_block_1b(X):\n",
        "    X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name='inception_3b_3x3_conv1')(X)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn1')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "    X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3b_3x3_conv2')(X_3x3)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn2')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "\n",
        "    X_5x5 = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3b_5x5_conv1')(X)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn1')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "    X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "    X_5x5 = Conv2D(64, (5, 5), data_format='channels_first', name='inception_3b_5x5_conv2')(X_5x5)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn2')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_pool_conv')(X_pool)\n",
        "    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_pool_bn')(X_pool)\n",
        "    X_pool = Activation('relu')(X_pool)\n",
        "    X_pool = ZeroPadding2D(padding=(4, 4), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_1x1_conv')(X)\n",
        "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_1x1_bn')(X_1x1)\n",
        "    X_1x1 = Activation('relu')(X_1x1)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ney2gJpq0_9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inception_block_1c(X):\n",
        "    X_3x3 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_3c_3x3',\n",
        "                           cv1_out=128,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=256,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(1, 1))\n",
        "\n",
        "    X_5x5 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_3c_5x5',\n",
        "                           cv1_out=32,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=64,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "    return inception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cMicv2oq0_9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inception_block_2a(X):\n",
        "    X_3x3 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_4a_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=192,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_5x5 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_4a_5x5',\n",
        "                           cv1_out=32,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=64,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = fr_utils.conv2d_bn(X_pool,\n",
        "                           layer='inception_4a_pool',\n",
        "                           cv1_out=128,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           padding=(2, 2))\n",
        "    X_1x1 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_4a_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgTKFN8yq0_-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inception_block_2b(X):\n",
        "    #inception4e\n",
        "    X_3x3 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_4e_3x3',\n",
        "                           cv1_out=160,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=256,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(1, 1))\n",
        "    X_5x5 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_4e_5x5',\n",
        "                           cv1_out=64,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=128,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "    return inception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOGVBEWQq0__"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inception_block_3a(X):\n",
        "    X_3x3 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_5a_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=384,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = fr_utils.conv2d_bn(X_pool,\n",
        "                           layer='inception_5a_pool',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_1x1 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_5a_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "\n",
        "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opx133zLq1AA"
      },
      "outputs": [],
      "source": [
        "def inception_block_3b(X):\n",
        "    X_3x3 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_5b_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=384,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = fr_utils.conv2d_bn(X_pool,\n",
        "                           layer='inception_5b_pool',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1))\n",
        "    X_pool = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = fr_utils.conv2d_bn(X,\n",
        "                           layer='inception_5b_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K38FbnO2q1AB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def triplet_loss(y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss\n",
        "\n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "\n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist) ,alpha)\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0))\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxV59r9Jq1AC"
      },
      "outputs": [],
      "source": [
        "def faceRecoModel(input_shape):\n",
        "    \"\"\"\n",
        "    Implementation of the Inception model used for FaceNet\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # First Block\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', data_format='channels_first')(X)\n",
        "    X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1),data_format='channels_first' )(X)\n",
        "    X = MaxPooling2D((3, 3), strides = 2, data_format='channels_first')(X)\n",
        "\n",
        "    # Second Block\n",
        "    X = Conv2D(64, (1, 1), strides = (1, 1), name = 'conv2', data_format='channels_first')(X)\n",
        "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
        "\n",
        "    # Second Block\n",
        "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv3', data_format='channels_first')(X)\n",
        "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
        "    X = MaxPooling2D(pool_size = 3, strides = 2,data_format='channels_first')(X)\n",
        "\n",
        "    # Inception 1: a/b/c\n",
        "    X = inception_block_1a(X)\n",
        "    X = inception_block_1b(X)\n",
        "    X = inception_block_1c(X)\n",
        "\n",
        "    # Inception 2: a/b\n",
        "    X = inception_block_2a(X)\n",
        "    X = inception_block_2b(X)\n",
        "\n",
        "    # Inception 3: a/b\n",
        "    X = inception_block_3a(X)\n",
        "    X = inception_block_3b(X)\n",
        "\n",
        "    # Top layer\n",
        "    X = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(128, name='dense_layer')(X)\n",
        "\n",
        "    # L2 normalization\n",
        "    X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
        "\n",
        "    # Create model instance\n",
        "    model = Model(inputs = X_input, outputs = X, name='FaceRecoModel')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhLOPRtWq1AD"
      },
      "source": [
        "Load the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MuWj5ZBq1AG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRn6f5R2xLqZ",
        "outputId": "8972abdd-b96b-4d16-b0e7-f485c1f49705"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_3EjA5zuq1AH",
        "outputId": "5cdbf86e-4360-4705-dac1-420070283bab"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "json_file = open('keras-facenet-h5/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights('keras-facenet-h5/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCFjis09q1AH"
      },
      "outputs": [],
      "source": [
        "FRmodel = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuieCDUoq1AI"
      },
      "source": [
        "We can use Face verification to verify identity and face recognition to get a person's name, we will create a database of images and convert them to encodings using the fucntion below, I have used a some images of teachers of Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOLsfNViq1AI"
      },
      "outputs": [],
      "source": [
        "def img_to_encoding(image_path, model):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
        "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
        "    x_train = np.expand_dims(img, axis=0)\n",
        "    embedding = model.predict_on_batch(x_train)\n",
        "    return embedding / np.linalg.norm(embedding, ord=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnbgOgx9q1AI"
      },
      "outputs": [],
      "source": [
        "database = {}\n",
        "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
        "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
        "# Load more images of passengers in this way whenver a passenger registers for first time and store in a vector db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6ep_WzKq1AJ"
      },
      "outputs": [],
      "source": [
        "def verify(image_path, identity, database, model):\n",
        "    \"\"\"\n",
        "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
        "\n",
        "    Arguments:\n",
        "        image_path -- path to an image\n",
        "        identity -- string, name of the person you'd like to verify the identity. Has to be an employee who works in the office.\n",
        "        database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
        "        model -- your Inception model instance in Keras\n",
        "\n",
        "    Returns:\n",
        "        dist -- distance between the image_path and the image of \"identity\" in the database.\n",
        "        door_open -- True, if the door should open. False otherwise.\n",
        "    \"\"\"\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "\n",
        "    dist = np.linalg.norm(encoding - database[identity])\n",
        "    print(dist)\n",
        "\n",
        "    if dist < 0.7:\n",
        "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
        "        door_open = True\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \", please go away\")\n",
        "        door_open = False\n",
        "\n",
        "    return dist, door_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ttfdHf-q1AJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "distance, door_open_flag = verify(\"images/camera_0.jpg\", \"younes\", database, FRmodel)\n",
        "assert np.isclose(distance, 0.5992949), \"Distance not as expected\"\n",
        "assert isinstance(door_open_flag, bool), \"Door open flag should be a boolean\"\n",
        "print(\"(\", distance, \",\", door_open_flag, \")\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_YoFSwNq1AJ"
      },
      "source": [
        "A function which recognizes who the person is from the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVhtxfqHq1AK"
      },
      "outputs": [],
      "source": [
        "def who_is_it(image_path, database, model):\n",
        "    \"\"\"\n",
        "    Implements face recognition for the metero by finding who is the person on the image_path image.\n",
        "\n",
        "    Arguments:\n",
        "        image_path -- path to an image\n",
        "        database -- database containing image encodings along with the name of the person on the image\n",
        "        model -- our Inception model instance in Keras\n",
        "\n",
        "    Returns:\n",
        "        min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
        "        identity -- string, the name prediction for the person on image_path\n",
        "    \"\"\"\n",
        "\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    min_dist = 100\n",
        "\n",
        "    # Loop over the database dictionary's names and encodings.\n",
        "    for (name, db_enc) in database.items():\n",
        "\n",
        "        dist = np.linalg.norm(db_enc - encoding)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "\n",
        "    if min_dist > 0.7:\n",
        "        print(\"Not in the database.\")\n",
        "    else:\n",
        "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "\n",
        "    return min_dist, identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIWGvh77q1AK"
      },
      "outputs": [],
      "source": [
        "test1 = who_is_it(\"images/camera_0.jpg\", database, FRmodel)\n",
        "assert np.isclose(test1[0], 0.5992946)\n",
        "assert test1[1] == 'younes'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
